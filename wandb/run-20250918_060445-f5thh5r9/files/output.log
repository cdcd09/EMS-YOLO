Overriding model.yaml nc=80 with nc=12

                 from  n    params  module                                  arguments
  0                -1  1      9536  models.common.Conv_1                    [3, 64, 7, 2]
  1                -1  1     78208  models.common.BasicBlock_2              [64, 64, 3, 2]
  2                -1  1     73984  models.common.BasicBlock_2              [64, 64, 3, 1]
  3                -1  1    230144  models.common.BasicBlock_2              [64, 128, 3, 2]
  4                -1  1    295424  models.common.BasicBlock_2              [128, 128, 3, 1]
  5                -1  1    919040  models.common.BasicBlock_2              [128, 256, 3, 2]
  6                -1  1   1180672  models.common.BasicBlock_2              [256, 256, 3, 1]
  7                -1  1   3673088  models.common.BasicBlock_2              [256, 512, 3, 2]
  8                -1  1   4720640  models.common.BasicBlock_2              [512, 512, 3, 1]
  9                -1  1   1902080  models.common.BasicBlock_2              [512, 256, 3, 1]
 10                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]
 11                -2  1     82688  models.common.BasicBlock_2              [256, 128, 1, 1]
 12                -1  1         0  models.common.Sample                    [None, 2, 'nearest']
 13           [-1, 6]  1         0  models.common.Concat                    [2]
 14                -1  1    885248  models.common.Conv                      [384, 256, 3, 1]
 15          [14, 10]  1     39270  models.yolo.Detect                      [12, [[10, 14, 23, 27, 37, 58], [81, 82, 135, 169, 344, 319]], [256, 512]]
Model Summary: 191 layers, 15270694 parameters, 15270694 gradients, 0.0 GFLOPs

Scaled weight_decay = 0.0005
[34m[1moptimizer:[0m SGD with parameter groups 29 weight, 31 weight (no decay), 31 bias
/content/EMS-YOLO/utils/augmentations.py:31: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression
  A.ImageCompression(quality_lower=75, p=0.0)],
/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.
  self._set_keys()
[34m[1malbumentations: [0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))
[34m[1mtrain: [0mScanning 'obstacles-5/train/labels' images and labels...3975 found, 0 missing, 0 empty, 6 corrupted: 100% 3975/3975 [00:00<00:00, 7714.75it/s]
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f2275e_d20170225_m202342_c001_v0001038_t0018_png.rf.bd81586483e1a69234381b26ba5f169e.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f2275e_d20170225_m202342_c001_v0001038_t0018_png.rf.e44cf69290700110cfa4c4f1ea09d8df.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f2275e_d20170225_m202342_c001_v0001038_t0018_png.rf.ffd2de6425d7e3a04e20fc0e5b9c46d1.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f22958_d20170225_m202613_c001_v0001038_t0018_png.rf.0388dc440c235bebd0ab776d81f66507.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f22958_d20170225_m202613_c001_v0001038_t0018_png.rf.3d7ad7214fe93b915079020364d885d0.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f22958_d20170225_m202613_c001_v0001038_t0018_png.rf.49c7bb13abc39acc54b25c086bbf1165.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/images69_jpg.rf.1aae0cc4f60597ca5c0a2dcd844d2a8c.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/images69_jpg.rf.b151c6a9237ea0246195f671cce1dcb0.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/images69_jpg.rf.dcadb9014f9bc4b37c5ca2a95fa774fc.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/youtube-11_jpg.rf.563acfd2229fe06cc8630b0b11b9d69b.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/youtube-11_jpg.rf.5adb045903c2e0bcb0f21fe740b55397.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/youtube-11_jpg.rf.ddb0a77a001ffcf2a61fb096f5cc6a5d.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mNew cache created: obstacles-5/train/labels.cache
[34m[1mval: [0mScanning 'obstacles-5/valid/labels' images and labels...200 found, 0 missing, 0 empty, 0 corrupted: 100% 200/200 [00:00<00:00, 3929.59it/s]
[34m[1mval: [0mWARNING: obstacles-5/valid/images/4_z8126b7d060d92d74599e0618_f105bec8d654623bd_d20170228_m032421_c001_v0001038_t0052_png.rf.9ea9d6941df4a949ff5ea3c92a2ca60c.jpg: 1 duplicate labels removed
[34m[1mval: [0mNew cache created: obstacles-5/valid/labels.cache
Plotting labels to runs/train/exp15/labels.jpg...

[34m[1mAutoAnchor: [0m2.88 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…
/content/EMS-YOLO/train.py:265: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=cuda)
Image sizes 640 train, 640 val
Using 4 dataloader workers
Logging results to [1mruns/train/exp15[0m
Starting training for 200 epochs...

     Epoch   gpu_mem       box       obj       cls    labels  img_size
  0%|          | 0/249 [00:00<?, ?it/s]                                         /content/EMS-YOLO/train.py:317: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp.autocast(enabled=cuda):
     0/199     35.5G    0.1099   0.08769   0.06651        37       640:   0%|   /content/EMS-YOLO/train.py:317: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp.autocast(enabled=cuda):
Exception in thread Thread-12 (plot_images):
Traceback (most recent call last):
  File "/usr/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/content/EMS-YOLO/utils/plots.py", line 217, in plot_images
    annotator.text((x + 5, y + 5 + h), text=Path(paths[i]).name[:40], txt_color=(220, 220, 220))  # filenames
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/EMS-YOLO/utils/plots.py", line 116, in text
    w, h = self.font.getsize(text)  # text width, height
           ^^^^^^^^^^^^^^^^^
AttributeError: 'FreeTypeFont' object has no attribute 'getsize'
     0/199     35.5G    0.1081   0.08833   0.06655        32       640:   1%|   Exception in thread Thread-13 (plot_images):
Traceback (most recent call last):
  File "/usr/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/content/EMS-YOLO/utils/plots.py", line 217, in plot_images
    annotator.text((x + 5, y + 5 + h), text=Path(paths[i]).name[:40], txt_color=(220, 220, 220))  # filenames
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/EMS-YOLO/utils/plots.py", line 116, in text
    w, h = self.font.getsize(text)  # text width, height
           ^^^^^^^^^^^^^^^^^
AttributeError: 'FreeTypeFont' object has no attribute 'getsize'
     0/199     37.6G    0.1083   0.08922   0.06646        40       640:   1%|   Exception in thread Thread-14 (plot_images):
Traceback (most recent call last):
  File "/usr/lib/python3.12/threading.py", line 1075, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.12/threading.py", line 1012, in run
    self._target(*self._args, **self._kwargs)
  File "/content/EMS-YOLO/utils/plots.py", line 217, in plot_images
    annotator.text((x + 5, y + 5 + h), text=Path(paths[i]).name[:40], txt_color=(220, 220, 220))  # filenames
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/content/EMS-YOLO/utils/plots.py", line 116, in text
    w, h = self.font.getsize(text)  # text width, height
           ^^^^^^^^^^^^^^^^^
AttributeError: 'FreeTypeFont' object has no attribute 'getsize'
     0/199     39.8G   0.09846   0.05864   0.04659         1       640: 100%|â–ˆâ–ˆâ–ˆ
               Class     Images     Labels          P          R     mAP@.5 mAP@
Traceback (most recent call last):
  File "/content/EMS-YOLO/train.py", line 628, in <module>
    main(opt)
  File "/content/EMS-YOLO/train.py", line 525, in main
    train(opt.hyp, opt, device, callbacks)
  File "/content/EMS-YOLO/train.py", line 356, in train
    results, maps, _ = val.run(data_dict,
                       ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/content/EMS-YOLO/val.py", line 177, in run
    for batch_i, (im, targets, paths) in enumerate(pbar):
                 ^^^^^^^^^^^^^^^^^^^^
ValueError: too many values to unpack (expected 3)
