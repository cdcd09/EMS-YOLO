Overriding model.yaml nc=80 with nc=12

                 from  n    params  module                                  arguments
  0                -1  1      9536  models.common.Conv_1                    [3, 64, 7, 2]
  1                -1  1     78208  models.common.BasicBlock_2              [64, 64, 3, 2]
  2                -1  1     73984  models.common.BasicBlock_2              [64, 64, 3, 1]
  3                -1  1    230144  models.common.BasicBlock_2              [64, 128, 3, 2]
  4                -1  1    295424  models.common.BasicBlock_2              [128, 128, 3, 1]
  5                -1  1    919040  models.common.BasicBlock_2              [128, 256, 3, 2]
  6                -1  1   1180672  models.common.BasicBlock_2              [256, 256, 3, 1]
  7                -1  1   3673088  models.common.BasicBlock_2              [256, 512, 3, 2]
  8                -1  1   4720640  models.common.BasicBlock_2              [512, 512, 3, 1]
  9                -1  1   1902080  models.common.BasicBlock_2              [512, 256, 3, 1]
 10                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]
 11                -2  1     82688  models.common.BasicBlock_2              [256, 128, 1, 1]
 12                -1  1         0  models.common.Sample                    [None, 2, 'nearest']
 13           [-1, 6]  1         0  models.common.Concat                    [2]
 14                -1  1    885248  models.common.Conv                      [384, 256, 3, 1]
 15          [14, 10]  1     39270  models.yolo.Detect                      [12, [[10, 14, 23, 27, 37, 58], [81, 82, 135, 169, 344, 319]], [256, 512]]
Model Summary: 191 layers, 15270694 parameters, 15270694 gradients, 0.0 GFLOPs

Scaled weight_decay = 0.0005
[34m[1moptimizer:[0m SGD with parameter groups 29 weight, 31 weight (no decay), 31 bias
/content/EMS-YOLO/utils/augmentations.py:31: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression
  A.ImageCompression(quality_lower=75, p=0.0)],
/usr/local/lib/python3.12/dist-packages/albumentations/core/composition.py:331: UserWarning: Got processor for bboxes, but no transform to process it.
  self._set_keys()
[34m[1malbumentations: [0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))
[34m[1mtrain: [0mScanning 'obstacles-5/train/labels.cache' images and labels... 3975 found, 0 missing, 0 empty, 6 corrupted: 100% 3975/3975 [00:00<?, ?it/s]
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f2275e_d20170225_m202342_c001_v0001038_t0018_png.rf.bd81586483e1a69234381b26ba5f169e.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f2275e_d20170225_m202342_c001_v0001038_t0018_png.rf.e44cf69290700110cfa4c4f1ea09d8df.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f2275e_d20170225_m202342_c001_v0001038_t0018_png.rf.ffd2de6425d7e3a04e20fc0e5b9c46d1.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f22958_d20170225_m202613_c001_v0001038_t0018_png.rf.0388dc440c235bebd0ab776d81f66507.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f22958_d20170225_m202613_c001_v0001038_t0018_png.rf.3d7ad7214fe93b915079020364d885d0.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/4_z8126b7d060d92d74599e0618_f109cae5016f22958_d20170225_m202613_c001_v0001038_t0018_png.rf.49c7bb13abc39acc54b25c086bbf1165.jpg: 2 duplicate labels removed
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/images69_jpg.rf.1aae0cc4f60597ca5c0a2dcd844d2a8c.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/images69_jpg.rf.b151c6a9237ea0246195f671cce1dcb0.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/images69_jpg.rf.dcadb9014f9bc4b37c5ca2a95fa774fc.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/youtube-11_jpg.rf.563acfd2229fe06cc8630b0b11b9d69b.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/youtube-11_jpg.rf.5adb045903c2e0bcb0f21fe740b55397.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mtrain: [0mWARNING: obstacles-5/train/images/youtube-11_jpg.rf.ddb0a77a001ffcf2a61fb096f5cc6a5d.jpg: ignoring corrupt image/label: only integer scalar arrays can be converted to a scalar index
[34m[1mval: [0mScanning 'obstacles-5/valid/labels.cache' images and labels... 200 found, 0 missing, 0 empty, 0 corrupted: 100% 200/200 [00:00<?, ?it/s]
[34m[1mval: [0mWARNING: obstacles-5/valid/images/4_z8126b7d060d92d74599e0618_f105bec8d654623bd_d20170228_m032421_c001_v0001038_t0052_png.rf.9ea9d6941df4a949ff5ea3c92a2ca60c.jpg: 1 duplicate labels removed
Plotting labels to runs/train/exp19/labels.jpg...

[34m[1mAutoAnchor: [0m2.88 anchors/target, 0.999 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…
/content/EMS-YOLO/train.py:265: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = amp.GradScaler(enabled=cuda)
Image sizes 640 train, 640 val
Using 4 dataloader workers
Logging results to [1mruns/train/exp19[0m
Starting training for 50 epochs...

     Epoch   gpu_mem       box       obj       cls    labels  img_size
  0%|          | 0/249 [00:00<?, ?it/s]                                         /content/EMS-YOLO/train.py:317: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp.autocast(enabled=cuda):
      0/49     35.5G    0.1102   0.08744   0.06658        37       640:   0%|   /content/EMS-YOLO/train.py:317: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with amp.autocast(enabled=cuda):
      0/49     39.7G   0.09963   0.05847   0.05195        34       640:  61%|â–ˆâ–ˆâ–ˆ
Traceback (most recent call last):
  File "/content/EMS-YOLO/train.py", line 628, in <module>
    main(opt)
  File "/content/EMS-YOLO/train.py", line 525, in main
    train(opt.hyp, opt, device, callbacks)
  File "/content/EMS-YOLO/train.py", line 330, in train
    scaler.step(optimizer)  # optimizer.step
    ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py", line 465, in step
    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py", line 359, in _maybe_opt_step
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py", line 359, in <genexpr>
    if not sum(v.item() for v in optimizer_state["found_inf_per_device"].values()):
               ^^^^^^^^
KeyboardInterrupt
